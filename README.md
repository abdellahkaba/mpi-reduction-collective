# MPI Collective Reduction avec Docker

[![MPI](https://img.shields.io/badge/MPI-Parallel%20Computing-blue)](https://www.open-mpi.org/)
[![Docker](https://img.shields.io/badge/Docker-Containerized-green)](https://www.docker.com/)

Un exemple de r√©duction collective MPI avec distribution intelligente des donn√©es et calcul intensif, ex√©cut√© dans un cluster Docker.

## üõ† Installation & Ex√©cution

    1. Lancer le cluster MPI:
        docker compose up --build -d
        
    2. Se connecter au n≈ìud ma√Ætre: 
        docker exec -it --user vagrant mpi-node1 bash
        
    3. Compiler le programme:
        mpicc collective_reduction.c -o collective_reduction -lm
        
    4. Ex√©cuter en parall√®le (4 processus):
        mpirun -np 4 -host mpi-node1,mpi-node2,mpi-node3,mpi-node4 ./collective_reduction

    5. Comparer avec la version s√©quentielle:
        mpirun -np 1 ./collective_reduction
    


## üìä R√©sultats de Performance

### Comparaison Monoprocesseur vs Parall√®le (4 n≈ìuds)

| M√©trique               | Parall√®le (4x) | S√©quentiel | Acc√©l√©ration |
|------------------------|---------------|------------|--------------|
| Temps total            | 0.201s        | 0.730s     | 3.62x        |
| Temps calcul moyen     | 0.191s        | 0.730s     | -            |
| Temps distribution     | 0.002s        | N/A        | -            |
| Somme finale           | 818.36        | 818.36     | -            |

**Efficacit√© parall√®le**: 90.5% (3.62x/4.00x th√©orique)

### Sortie Type

```plaintext
=== EX√âCUTION PARALL√àLE ===
[COLLECTIVE] Distribution des donn√©es...
[PROCESSUS 0] D√©but du calcul sur 250 √©l√©ments...
[PROCESSUS 0] Calcul termin√© en 0.194s, somme locale: 204.59
[COLLECTIVE] Somme globale finale: 818.36
Temps total: 0.201s
